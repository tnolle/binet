{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "from april.fs import BPIC_DIR\n",
    "from april.fs import EVENTLOG_DIR\n",
    "from april.fs import EventLogFile\n",
    "from april.fs import get_event_log_files\n",
    "from april.generation import CategoricalAttributeGenerator\n",
    "from april.generation.anomaly import *\n",
    "from april.processmining.log import EventLog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform BPIC XES Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to transform the BPIC XES files to JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xes_files = [\n",
    "    'BPIC12.xes.gz',\n",
    "    'BPIC13_closed_problems.xes.gz',\n",
    "    'BPIC13_incidents.xes.gz',\n",
    "    'BPIC13_open_problems.xes.gz',\n",
    "    'BPIC15_1.xes.gz',\n",
    "    'BPIC15_2.xes.gz',\n",
    "    'BPIC15_3.xes.gz',\n",
    "    'BPIC15_4.xes.gz',\n",
    "    'BPIC15_5.xes.gz',\n",
    "    'BPIC17.xes.gz',\n",
    "    'BPIC17_offer_log.xes.gz'\n",
    "]\n",
    "\n",
    "json_files = [\n",
    "    'bpic12-0.0-1.json.gz',\n",
    "    'bpic13-0.0-1.json.gz',\n",
    "    'bpic13-0.0-2.json.gz',\n",
    "    'bpic13-0.0-3.json.gz',\n",
    "    'bpic15-0.0-1.json.gz',\n",
    "    'bpic15-0.0-2.json.gz',\n",
    "    'bpic15-0.0-3.json.gz',\n",
    "    'bpic15-0.0-4.json.gz',\n",
    "    'bpic15-0.0-5.json.gz',\n",
    "    'bpic17-0.0-1.json.gz',\n",
    "    'bpic17-0.0-2.json.gz'\n",
    "]\n",
    "\n",
    "for xes_file, json_file in tqdm(list(zip(xes_files, json_files))):\n",
    "    event_log = EventLog.from_xes(os.path.join(BPIC_DIR, xes_file))\n",
    "    event_log.save_json(os.path.join(EVENTLOG_DIR, json_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the transformed logs to add the anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)  # This will ensure reproducibility\n",
    "ps = [0.3]\n",
    "event_log_paths = [e.path for e in get_event_log_files(EVENTLOG_DIR) if 'bpic' in e.name and e.p == 0.0]\n",
    "\n",
    "combinations = list(itertools.product(event_log_paths, ps))\n",
    "for event_log_path, p in tqdm(combinations, desc='Add anomalies'):\n",
    "    event_log_file = EventLogFile(event_log_path)\n",
    "    event_log = EventLog.from_json(event_log_path)\n",
    "\n",
    "    anomalies = [\n",
    "        SkipSequenceAnomaly(max_sequence_size=2),\n",
    "        ReworkAnomaly(max_distance=5, max_sequence_size=3),\n",
    "        EarlyAnomaly(max_distance=5, max_sequence_size=2),\n",
    "        LateAnomaly(max_distance=5, max_sequence_size=2),\n",
    "        InsertAnomaly(max_inserts=2),\n",
    "    ]\n",
    "\n",
    "    if event_log.num_event_attributes > 0:\n",
    "        anomalies.append(AttributeAnomaly(max_events=3, max_attributes=min(2, event_log.num_activities)))\n",
    "\n",
    "    for anomaly in anomalies:\n",
    "        # This is necessary to initialize the likelihood graph correctly\n",
    "        anomaly.activities = event_log.unique_activities\n",
    "        anomaly.attributes = [CategoricalAttributeGenerator(name=name, values=values) for name, values in\n",
    "                              event_log.unique_attribute_values.items() if name != 'name']\n",
    "\n",
    "    for case in tqdm(event_log):\n",
    "        if np.random.uniform(0, 1) <= p:\n",
    "            anomaly = np.random.choice(anomalies)\n",
    "            anomaly.apply_to_case(case)\n",
    "        else:\n",
    "            NoneAnomaly().apply_to_case(case)\n",
    "\n",
    "    event_log.save_json(str(EVENTLOG_DIR / f'{event_log_file.model}-{p}-{event_log_file.id}.json.gz'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
